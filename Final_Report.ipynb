{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Report.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TzNJDNdBSiXy",
        "Xe1hkEvOZgT8",
        "Hc-yvZ4qbkgh"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucaslzl/search_ia_p1/blob/master/Final_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uDgcJ3xfSwxh"
      },
      "source": [
        "# **Introduction to Artificial Intelligence - MO416A**\n",
        "**UNIVERSITY OF CAMPINAS**\n",
        "\n",
        "\n",
        "\n",
        "This work was completed by the following members:\n",
        "\n",
        "\n",
        "\n",
        "*   Aissa Hadj - 265189\n",
        "*   Lucas Zanco Ladeira - 188951\n",
        "*   Matheus Ferraroni - 212142\n",
        "*   Maria Vit√≥ria Rodrigues Oliveira - 262884\n",
        "*   Oscar Ciceri - 164786\n",
        "\n",
        "The original code of the project is located on a [repository inside Github](https://github.com/lucaslzl/search_ia_p1) and the video showing the search strategies working is on [youtube](https://youtu.be/ffuthDRn6lE). \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PyZsOrK6ovtL",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gqNsAEmhiWs1"
      },
      "source": [
        "![alt text](https://cdn02.nintendo-europe.com/media/images/10_share_images/games_15/nes_5/H2x1_NES_PacMan.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TzNJDNdBSiXy"
      },
      "source": [
        "# **I - Introduction**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FJnz5Eovcu6I"
      },
      "source": [
        "In this project, we choose to apply various search methods to the Pac-man game. Pac-man is a maze arcade game created in 1980 by Namco [[1]](https://en.wikipedia.org/wiki/Pac-Man). Pac-man is a character that must be placed in a maze that must collect pieces and find the exit (the goal) without being caught by moving ghosts. We set two objectives in this project. The first one aims to experiment with each one of the search methods in a practical way. Secondly, we want to determine which search algorithm, among the ones we selected, is best suited for the Pac-man game, according to the metrics and game conditions considered we will present shortly. \n",
        "\n",
        "\n",
        "The current report will be structured as follow. We will start by\n",
        "\n",
        "1. presenting how we modeled the game, then\n",
        "2. describing some of the most important components of our code implementation, \n",
        "3. giving the motivations for choosing the search methods we selected, \n",
        "4. showing the results found, and finally \n",
        "5. we will suggest which search method is best suited depending on the game conditions. \n",
        "\n",
        "We also wish to note here that the programming language for this project is Python version 3.8.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z1BNaG1xSq3j"
      },
      "source": [
        "# **II - Problem modeling**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2PyA-xdacGni"
      },
      "source": [
        "## **1 - General**\n",
        "\n",
        "In order to implement the Pac-man game, we decided to do the following modelization. \n",
        "\n",
        "The main goal of the problem is to find a path that leads to the goal in order to solve the maze and finish the game. The second objective of Pac-man is to collect as many points as possible while progressing inside the maze.\n",
        "\n",
        "We also defined a set of rules. First, Pac-man can move freely inside the white spaces in the maze. However, it can't go back and revisit already visited nodes. As with the original game, there are ghosts inside the map. For simplification, we make the assumption that the ghosts are static and thus can't move. The problem is therefore deterministic, we can fully determine the next state of the game given the current state as well as the action chosen by Pac-man. \n",
        "\n",
        "Under those conditions, Pac-man will reason about the solution before actually adopting it. That means that, even before the game starts, we execute any of the search methods to select a path from the starting position to the goal position. Once the search is complete, we provide a list of actions for Pac-man to follow in order to solve the maze. \n",
        "\n",
        "The other two important game conditions, whether there is a countdown (a time limit) for Pac-man to reach the goal, or Pac-man must collect the maximum number of points, will be discussed later in the report. Those two conditions will guide us in determining which search method is more appropriate by adopting either one of those constraints.\n",
        "\n",
        "Below, we briefly discuss some of the most important elements of the problem.\n",
        "\n",
        "**The maze:** In the game, there is a maze where Pac-man\n",
        "has to collect as many pieces (we use the term \"points\" in this project) as possible without being caught by one of the ghosts. The maze is defined in\n",
        "terms of a grid. The black-areas, in a Pac-Man game, are non-traversable walls. They are represented as a sequence of # symbols in the project. The pieces that Pac-man must collect in the maze are represented as \"P\" letters in our mazes. We also note that, under our game conditions, the ghosts present in the mazes are frozen. This means that they can't move and, for simplicity, we decided to replace them with walls. Pac-man can't go through them that way. Below is an example of a representation of a maze. When the game begins, Pac-man starts at the position described with the \"S\" letter and must finish the game by reaching the goal position (\"G\" letter in the maze). Below, we give more details about the implementation of the maze inside the file \"map.py\". We also wish to note that, in the project, we use the term \"map\" to designate the maze.\n",
        "\n",
        "![alt text](https://github.com/lucaslzl/search_ia_p1/blob/master/maps/example%20of%20maze.png?raw=true)\n",
        "\n",
        "\n",
        "**Actions:** In this game, there are in total 4 possible actions that Pac-man can choose: left, right, down, or up in that order. Depending on the position of Pac-man in the maze, there might be fewer actions allowed. For instance, if Pac-man reaches a wall, only sideway movements are allowed. \n",
        "\n",
        "**Nodes:** The nodes are composed by a state, a parent node, a path cost, a depth and a list of available actions. The node can be used to reconstruct the path used to achieve the goal and expand a node using the available actions.\n",
        "\n",
        "**State:** The state is composed by the model of the scenario, points collected, points left, cost and information about the position of the actual state, start, goal, points and walls. The actual position, goal, start and points are represented as a pair of two coordinates (i, j) representing its row and column inside the map. The collected points is an integer and points left is a list of coordinates of these points. The state also control the positions on the a map that have never been visited and positions that have been already passed. The state is also responsable for check if the goal position has been achieved or not. The state check if a position on the map as already been visited, if it has the state does not return a valid action that allow a next state to go in that position, and this is used to avoid infinty loops.\n",
        "\n",
        "**Note on the nodes explored:** During the execution of the search strategies it is possible to arrive at the same location on the map using different paths. Some strategies can used an approach to avoid expand nodes that have similar states, avoiding waste of memory and time.\n",
        "\n",
        "Finally, in order to implement and evaluate the search methods for the problem described, we use the AIMA function library [2].\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qEvFcd5jdROY"
      },
      "source": [
        "## **2 - Maps**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pMPJUgKIdh1b"
      },
      "source": [
        "The map.py class has maze interaction functions, which will be described below. First, the init function receives the map file content, initializes the variables, and calls the validation function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p20xvDtydjDu",
        "colab": {}
      },
      "source": [
        "def __init__(self, map_text=None):\n",
        "        self.map = None\n",
        "        self.start = None\n",
        "        self.goal = None\n",
        "        self.pos = None\n",
        "        self.points_pos = []\n",
        "        self.points = 0\n",
        "        self.cost_till_here = 0\n",
        "        self.hashed = None\n",
        "\n",
        "        if map_text!=None:\n",
        "            self.validateMap(map_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PhyHYSKJdnml"
      },
      "source": [
        "The validate function verifies if the maze is valid, with walls on the sides, all the lines and colums with the same size and if it contains a start and a goal. Then, it saves the Goal and Point position in the map, and expresses these locations by 3 and 1, respectively. It sets up a \"0\" value where there is a barrier and \"1\" value where there is a space. Besides that, the start point (S) is described as \"2\".\n",
        "\n",
        "It is important to notice that the walls and free positions on the maze are saved as matrix, the current position, start position and goal are saved as a set of coordinates and the points on the maze as a list of coordinates.\n",
        "\n",
        "The script below exhibits this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NFeYyryndp0a",
        "colab": {}
      },
      "source": [
        "def validateMap(self, m):\n",
        "        m = m.split(\"\\n\")\n",
        "\n",
        "        for i in range(1,len(m),1):\n",
        "            if len(m[i])!=len(m[0]):\n",
        "                raise Exception(\"Map lines have different sizes.\")\n",
        "\n",
        "        i = 0\n",
        "        j = 0\n",
        "\n",
        "        self.map = []\n",
        "        for line in m:\n",
        "            j=0\n",
        "            self.map.append([])\n",
        "            for c in line:\n",
        "                if ((i==0 or i==len(m)-1) and c!=\"#\") or ((j==0 or j==len(m[i])-1) and c!=\"#\"):\n",
        "                    raise Exception(\"Maze borders must be '#'.\")\n",
        "                if c == \"#\":\n",
        "                    self.map[i].append(0)\n",
        "                elif c == \" \":\n",
        "                    self.map[i].append(1)\n",
        "                elif c.upper() == \"S\":\n",
        "                    if self.start!=None:\n",
        "                        raise Exception(\"Only one Start is allowed.\")\n",
        "                    self.map[i].append(2)\n",
        "                    self.start = [j,i]\n",
        "                    self.pos = [j,i]\n",
        "                elif c.upper() == \"G\":\n",
        "                    if self.goal!=None:\n",
        "                        raise Exception(\"Only one Goal is allowed.\")\n",
        "                    self.map[i].append(3)\n",
        "                    self.goal = [j,i]\n",
        "                elif c.upper() == \"P\":\n",
        "                    self.map[i].append(1)\n",
        "                    self.points_pos.append([j,i])\n",
        "                else:\n",
        "                    raise Exception(\"Invalid map char: \"+c)\n",
        "\n",
        "                j += 1\n",
        "            i += 1\n",
        "\n",
        "        if self.start==None or self.goal==None:\n",
        "            raise Exception(\"Start and Goal must be provided\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sewcDEzMdur1"
      },
      "source": [
        "Then, all the positions on the map are shown as integers as displayed below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k1qPyMfedxHP",
        "colab": {}
      },
      "source": [
        "00000000000\n",
        "01111111110\n",
        "01000100010\n",
        "01011111010\n",
        "01010001010\n",
        "01011311010\n",
        "01000000010\n",
        "01111211110\n",
        "00000000000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SVt-6zsQ-6Nz"
      },
      "source": [
        "There are also functions used to print the maze in a more human way, allowing the users to easily identify what is happening. This can be seen below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y_156tk-d2KD",
        "colab": {}
      },
      "source": [
        "def printVisual(self):\n",
        "        for i in range(len(self.map)):\n",
        "            for j in range(len(self.map[i])):\n",
        "                c = None\n",
        "                if self.map[i][j]==0:\n",
        "                    c = \"#\"\n",
        "                elif self.map[i][j]==1:\n",
        "                    c = \" \"\n",
        "                elif self.map[i][j]==2:\n",
        "                    c = \"S\"\n",
        "                elif self.map[i][j]==3:\n",
        "                    c = \"G\"\n",
        "                elif self.map[i][j]==4:\n",
        "                    c = \"$\"\n",
        "\n",
        "                for p in self.getPointsLeft():\n",
        "                    if j==p[0] and i==p[1]:\n",
        "                        c = \"P\"\n",
        "\n",
        "                if i==self.pos[1] and j==self.pos[0]:\n",
        "                    if self.pos!=self.start:\n",
        "                        c = \"X\"\n",
        "                print(c,end=\"\")\n",
        "            print(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TzbEjUGtdzQ1"
      },
      "source": [
        "In the code below, it was verified the options of actions, depending on the self-position. If on the left/right/up/down there is no barrier and it was not a covered space, then it can be considered as a movement option.\n",
        "\n",
        "The cgetActions function is used to get the valid actions to a state. It was designed to be as fast as possible and easy to understand. The algorithm just gets the current position and checks if an adjacent position is a wall or has been already visited. If these two statements are false, the action that leads to that position is valid. Otherwise the state does not return this position."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2P9am7OVd9n_",
        "colab": {}
      },
      "source": [
        "def getActions(self):\n",
        "        ret1 = []\n",
        "        ret2 = []        \n",
        "        \n",
        "        # LEFT\n",
        "        val = self.map[self.pos[1]][self.pos[0]-1]\n",
        "        if val!=0 and val!=4:\n",
        "            ret1.append(\"E\")\n",
        "            ret2.append(1)\n",
        "        \n",
        "        # RIGHT\n",
        "        val = self.map[self.pos[1]][self.pos[0]+1]\n",
        "        if val!=0 and val!=4:\n",
        "            ret1.append(\"D\")\n",
        "            ret2.append(2)\n",
        "        # UP\n",
        "        val = self.map[self.pos[1]+1][self.pos[0]]\n",
        "        if val!=0 and val!=4:\n",
        "            ret1.append(\"B\")\n",
        "            ret2.append(3)\n",
        "\n",
        "        # DOWN\n",
        "        val = self.map[self.pos[1]-1][self.pos[0]]\n",
        "        if val!=0 and val!=4:\n",
        "            ret1.append(\"C\")\n",
        "            ret2.append(4)\n",
        "\n",
        "        return ret1, ret2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ucPAVay5mRY4"
      },
      "source": [
        "The act function alters the state by applying a valid action. The first step of the act is to check if the problem is solved. If it is already solved nothing is done. If it is not solved yet, the function verifies whether the next position is available. Then, the current position is marked with the number \"4\" (to show that this position has been visited), and the next position is marked as self-position. Besides that, the collectPoint function is called."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pQqB_2Q5mT4O",
        "colab": {}
      },
      "source": [
        "def act(self, action):\n",
        "\n",
        "    if self.solved():\n",
        "        print(\"Maze already completed.\")\n",
        "        return False\n",
        "\n",
        "    if action==1 or action==\"E\": #moving left\n",
        "        val = self.map[self.pos[1]][self.pos[0]-1]\n",
        "        if val==0 or val==4: #check if is blocked or already passed\n",
        "            return False\n",
        "        self.map[self.pos[1]][self.pos[0]] = 4 # mark as passed\n",
        "        self.pos = [self.pos[0]-1,self.pos[1]] # update position\n",
        "        self.collectPoint(self.pos[1],self.pos[0])\n",
        "        return True\n",
        "    elif action==2 or action==\"D\": #moving right\n",
        "        val = self.map[self.pos[1]][self.pos[0]+1]\n",
        "        if val==0 or val==4:\n",
        "            return False\n",
        "        self.map[self.pos[1]][self.pos[0]] = 4\n",
        "        self.pos = [self.pos[0]+1,self.pos[1]]\n",
        "        self.collectPoint(self.pos[1],self.pos[0])\n",
        "        return True\n",
        "    elif action==3 or action==\"B\": #moving down\n",
        "        val = self.map[self.pos[1]+1][self.pos[0]]\n",
        "        if val==0 or val==4:\n",
        "            return False\n",
        "        self.map[self.pos[1]][self.pos[0]] = 4\n",
        "        self.pos = [self.pos[0],self.pos[1]+1]\n",
        "        self.collectPoint(self.pos[1],self.pos[0])\n",
        "        return True\n",
        "    elif action==4 or action==\"C\": #moving up\n",
        "        val = self.map[self.pos[1]-1][self.pos[0]]\n",
        "        if val==0 or val==4:\n",
        "            return False\n",
        "        self.map[self.pos[1]][self.pos[0]] = 4\n",
        "        self.pos = [self.pos[0],self.pos[1]-1]\n",
        "        self.collectPoint(self.pos[1],self.pos[0])\n",
        "        return True\n",
        "\n",
        "    raise Exception(\"Action unknown\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HdXpeglEmiU6"
      },
      "source": [
        "The collectpoint function verifies if the self-position is a Point (P) using the points_pos matrix. If it is, the state increments its points counter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7zYEaJhbmk3n",
        "colab": {}
      },
      "source": [
        "def collectPoint(self, i, j):\n",
        "    ini = len(self.points_pos)\n",
        "    self.points_pos = [a for a in self.points_pos if not(a[0]==j and a[1]==i)]\n",
        "    if len(self.points_pos)!=ini:\n",
        "        self.points += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jSvpUOgBmnA4"
      },
      "source": [
        "The sim function returns a map object with the action applied. This is done in order to create new states faster, by copying the current state and just applying an action to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XPTqSjKqmoeF",
        "colab": {}
      },
      "source": [
        "def sim(self, action): \n",
        "    ret = self.copy()\n",
        "    ret.act(action)\n",
        "    ret.cost_till_here = self.cost_till_here+1\n",
        "    ret.hashed = None\n",
        "    return ret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G_Hdxl_9mrXC"
      },
      "source": [
        "Finally, the solved function checks whether the self-position is the Goal (G)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G8ON4VgImtVW",
        "colab": {}
      },
      "source": [
        "def solved(self):\n",
        "    return self.pos[0]==self.goal[0] and self.pos[1]==self.goal[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lqicntizoQcO"
      },
      "source": [
        "## **3 - Methodology for the search comparison**\n",
        "\n",
        "**Maps:** To help us decide which search method is optimal in the Pac-man game, we will experiment with various conditions. We designed 9 different maps, classified under two groups. The first group is composed of 4 maps: map4, map10, map11, and map12. Those are empty maps. Meaning they contain no walls inside them. The second group is composed of 5 maps containing walls strategically placed to test the effectiveness of the approaches choosen.\n",
        "The maps are of different sizes in length and width to see the effect of the maze size on each search method.\n",
        "\n",
        "Besides, the maps contain 10 collectable points each. Some of the points may not be reachable following the rules applied in this project.\n",
        "\n",
        "**Metrics:** The algorithms have been executed 10 times on each map in order to determine a good confidence interval. To compare the different search methods, we will measure the following metrics:\n",
        "\n",
        "\n",
        "1. Time (sec, seconds): it's the execution time from start to finish of each search method to solve the maze\n",
        "2. Nodes: it's the number of nodes generated by each search method\n",
        "3. Expanded nodes: it's the number of nodes each search method explored to find a solution\n",
        "4. Nodes per second (Nodes/sec): Number of nodes generated by second\n",
        "5. Expanded nodes per second (Expanded nodes/sec): Number of nodes explored by second\n",
        "6. Action: it's the total number of actions Pac-man has to take to go from the initial position to the goal\n",
        "7. Points: it's the number of points Pac-man collected in its path to the goal\n",
        "\n",
        "The metric \"number of nodes\" will help us measure the memory used by each search method to find a solution. A high number of generated nodes means a high use of memory.\n",
        "\n",
        "The metric \"nodes explored per second\" can be used to determine how fast a search method selects a node to explore. A high number of nodes explored per second means that the search method can check more nodes in less time. This can change drastically if the search method is performing some kind of ordering to select the next node to explore.\n",
        "\n",
        "\n",
        "With all those metrics measured during the simulations, we would then be able to compare the performance of each search method under different hypotheses.\n",
        "\n",
        "\n",
        "We run the independent experiments all at once (using the script located inside \"execute.sh\") inside a single machine. It's a MacBook Air containing a 1.6 GHz Intel Core I5, and 8 Gb of RAM. To prevent any skewing of the results, we closed all other applications, so that no other script was running in parallel while conducting the experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ywGTkmlQQ9Yd"
      },
      "source": [
        "# **III - Search Methods Considered**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pT9af0cxb8qS"
      },
      "source": [
        "In this problem, we selected the following search methods: \n",
        "\n",
        "\n",
        "\n",
        "1. Breadth-first search\n",
        "2. Depth-first search\n",
        "3. A*1\n",
        "4. A*2\n",
        "5. Local beam search\n",
        "6. Hill climbing\n",
        "\n",
        "Below we describe each one of them, explain why they were chosen for this project, as well as showing the script implemented in Python. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6D7aQm3iVvjO"
      },
      "source": [
        "## **1 - Breadth-first search**\n",
        "\n",
        "For the performance measures, we consider $b$ the average number of successors and $d$ shallowest depth of the solution.\n",
        "\n",
        "Breadth-first Search\n",
        "This strategy has the capability to search in a graph-like (graph or tree) data structure. The distance from a node to the starting node is used to explore the data. The key idea is that it may not explore a node of a farther distance without exploring every node from the same distance. A queue structure is usually utilized as the First In First Out (FIFO) rule is followed.\n",
        "\n",
        "**Performance measures:**\n",
        "\n",
        "**Completeness**: Yes, this strategy is classified as complete as it finds the goal if it exists.\n",
        "\n",
        "**Optimization:** Yes, only if all the paths have the same cost.\n",
        "\n",
        "**Time complexity:** $ O(b^d) $\n",
        "\n",
        "**Memory complexity:** $ O(b^d) $\n",
        "\n",
        "Below we provide the implementation of the breadth-first search in Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zzXEXl_uWgMw",
        "colab": {}
      },
      "source": [
        "def BreadthFirst(problem):\n",
        "\n",
        "    checkeds = []\n",
        "    frontier = deque([Node(problem.initial)])\n",
        "\n",
        "    while frontier:\n",
        "\n",
        "        node = frontier.popleft()\n",
        "\n",
        "        if problem.goal_test(node.state):\n",
        "            return node\n",
        "\n",
        "        frontier.extend(node.expand(problem))\n",
        "\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KvvgPZYxWo4-"
      },
      "source": [
        "## **2 - Depth-first search**\n",
        "\n",
        "This strategy has the capability to search in a graph-like data structure. The distance from a node to the starting node is used to explore the data. The key idea is that it will explore a node with a farther distance without exploring any other node from the same distance if possible. A stack structure is usually utilized as the Last In First Out (LIFO) rule is followed.\n",
        "\n",
        "**Performance measures:**\n",
        "\n",
        "**Completeness:** No, it may create an infinite loop if a branch has no end.\n",
        "\n",
        "**Optimization:** No, there is no guarantee that will find the best solution even if all paths have the same cost.\n",
        "\n",
        "**Time complexity:** $ O(b^d) $\n",
        "\n",
        "**Memory complexity:** $ O(bd) $\n",
        "\n",
        "Below we provide the implementation of the depth-first search in Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G6rLovuTW58_",
        "colab": {}
      },
      "source": [
        "def DepthFirst(problem):\n",
        "\n",
        "    frontier = [Node(problem.initial)]\n",
        "\n",
        "    while frontier:\n",
        "\n",
        "        node = frontier.pop()\n",
        "\n",
        "        if problem.goal_test(node.state):\n",
        "            return node\n",
        "\n",
        "        frontier.extend(node.expand(problem))\n",
        "\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xCBtPi4NW9Za"
      },
      "source": [
        "## **3 - A-Star**\n",
        "\n",
        "### **Strategy**\n",
        "\n",
        "This solution employs the best-first graph search or greedy search, thus the node expansions are given by the lowest scores first policy.\n",
        "\n",
        "This policy sorts the nodes, employs a mechanism that minimizes the function f(n). For example, the breadth-first search occurs when f(n)=node.depth.\n",
        "\n",
        "Moreover, the function f(n) \"memorizes\" the nodes previously computed, in order to examine the f values and recover the path.\n",
        "\n",
        "The following code shows the implementation of the best-first graph search:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ChF_TzYkXW9i",
        "colab": {}
      },
      "source": [
        "def best_first_graph_search(problem, f, display=False):\n",
        "    # Nodes in cache\n",
        "    f = memoize(f, 'f') \n",
        "    node = Node(problem.initial)\n",
        "    # Priority queue giving by the lowest score in f(n)=g(n)+h(n)\n",
        "    frontier = PriorityQueue('min', f)\n",
        "    # Initial node\n",
        "    frontier.append(node)\n",
        "    explored = set()\n",
        "    # While node goal different goal state\n",
        "    while frontier:\n",
        "        node = frontier.pop()\n",
        "        # If node goal equal node state, return node\n",
        "        if problem.goal_test(node.state):\n",
        "            if display:\n",
        "                print(len(explored), \"paths have been expanded and\", len(frontier), \"paths remain in the frontier\")\n",
        "            return node\n",
        "        # else, add node to the priority queue\n",
        "        explored.add(node.state)\n",
        "        for child in node.expand(problem):\n",
        "            if child.state not in explored and child not in frontier:\n",
        "                frontier.append(child)\n",
        "            elif child in frontier:\n",
        "                if f(child) < frontier[child]:\n",
        "                    del frontier[child]\n",
        "                    frontier.append(child)\n",
        "    return None\n",
        "\n",
        "def Astar(problem, display=False):\n",
        "    h = None\n",
        "    h = memoize(h or problem.h, 'h')\n",
        "    fn = n.path_cost + h(n)\n",
        "    \n",
        "    return best_first_graph_search(problem, lambda n: fn, display)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AQGT8Ds4Xdlc"
      },
      "source": [
        "The A-Star strategy tries to expand the node, which is closest to the goal and also considers the cost to reach that node. This expansion policy means that the f function depends on two values.\n",
        "\n",
        "Thus, the evaluation of the nodes is done employing the function f(n):\n",
        "\n",
        "f(n) = g(n) + h(n)\n",
        "\n",
        "- g(n): cost to reach each node\n",
        "- h(n): cost to get from the node to the goal\n",
        "\n",
        "In this project, the function g(n) is equal to the path cost.\n",
        "\n",
        "The path cost of this solution increases by a value of 1 when the state changes by an action.\n",
        "\n",
        "Thus, the cost is uniform for every step in the path, since all steps have the same value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7BF0yO4EXgoZ",
        "colab": {}
      },
      "source": [
        "def path_cost(self, c, state1, action, state2):\n",
        "        return c + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RLPYftpCXhXn"
      },
      "source": [
        "Also, the node evaluation is given by a heuristic h(n), which assumes that the node closest to the goal is the fastest solution.\n",
        "\n",
        "The following sections show the two heuristics employed in this project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1QmUmQPsXkDI"
      },
      "source": [
        "### **A-Star 1**\n",
        "\n",
        "The A*1 heuristic employs the Euclidean distance, which calculates the straight line distance in a Cartesian plane.\n",
        "\n",
        "Thus, h1(n) is calculated as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "35PiawVDYGxa",
        "colab": {}
      },
      "source": [
        "def h1(self, node):\n",
        "    return node.state.getDistance()\n",
        "    \n",
        "def getDistance(self):\n",
        "    v = distance.euclidean(self.pos, self.goal)\n",
        "    return v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GzT_pI1bYKOQ"
      },
      "source": [
        "The A Search is complete and optimal when the function h(n) satisfies the following conditions:\n",
        "\n",
        "Consistent heuristic:$$h(n) \\leq  c(n, a, n') + h(n')$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mlz16YxJYNYw",
        "outputId": "8ac69ff0-eb0f-4cf4-f7c3-3c8ea2272a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "Image(\"https://raw.githubusercontent.com/lucaslzl/search_ia_p1/master/img/consistent.png\", width=500, height=200)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "height": 200,
              "width": 500
            }
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9IVQoGZCYQgU"
      },
      "source": [
        "In this case, the steps between the actual free space and the goal space can never be longer than the Euclidean distance.\n",
        "\n",
        "If\n",
        "\n",
        "- h(n) = Euclidean distance from node n to goal g\n",
        "\n",
        "- h(n') : Euclidean distance from node n' to goal g\n",
        "\n",
        "- c(n, a, n') = 1\n",
        "\n",
        "This heuristic, which employs the Euclidean distance, is a consistent heuristic due to in the best case when the actions to go from n to n' decreases the path in 1 step. We have that the c(n, a, n') + h(n') is equal to h(n)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pj4LHnTGYTx6"
      },
      "source": [
        "### **A-Star 2**\n",
        "\n",
        "The A*2 heuristic employs the Euclidean distance combined with a distance to reach a near point.\n",
        "\n",
        "Thus, h2(n) is calculated as:\n",
        "\n",
        "If\n",
        "\n",
        "- a = Euclidean distance from node n to goal g\n",
        "- b = Euclidean distance from node n to the nearest point p\n",
        "- c = Euclidean distance that point p to the goal g\n",
        "- v = b + c\n",
        "\n",
        "As shown the following figure:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l7uFeaplYpr0",
        "outputId": "d59dc136-befb-4e81-b7cc-2e8eb1d4eef9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "Image(\"https://raw.githubusercontent.com/lucaslzl/search_ia_p1/master/img/h2.png\", width=300, height=300)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "height": 300,
              "width": 300
            }
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HJxFURIBY8M8"
      },
      "source": [
        "The heuristic considers v, as the Euclidian distance to go from the node n to the point and after to the goal. These distances satisfy the following inequality:\n",
        "\n",
        "$$ a \\leq b + c$$ \n",
        "$$ a \\leq v $$\n",
        "\n",
        "However, the distance c is mapped to a smaller value equal to a, with the aim that the node considers the point and that the heuristic is consistent.\n",
        "\n",
        "The steps to calculate h2 are explained below.\n",
        "\n",
        "Find the distance from the node n to the nearest point p (distance b). Subsequently, calculate the distance from that point p to the goal g (distance c).\n",
        "If there are no more points on the map, it employs the Euclidian distance between the node n and the goal g (distance a), equal to h1.\n",
        "Calculate x as the division between a and v. The value of x is a number between 0 to 1 since a is always less or equal to c. Thus, when the node is closer to the point, the x value will approach 1.\n",
        "\n",
        "$$ x = \\frac{a}{v} = \\frac{a}{b+c}: 0 < x \\leq 1 $$\n",
        "\n",
        "Calculate the complement of x a in order to penalize the distance c. Thus a higher the distance to c, the value of x will approach 1.\n",
        "$$ x' = 1 - x $$\n",
        "Finally, we consider x value as a percentage of c. The heuristic is consistent the calculated value need to be higher than c; then we add c to the percentage previously calculated as:\n",
        "$$ h_2 = c + c\\cdot(1-x): c < h_2 < 2 \\cdot c$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tvaii9AcY-ZW",
        "colab": {}
      },
      "source": [
        "def h2(self, node):\n",
        "    return node.state.getDistancePoints()\n",
        "\n",
        "def getDistancePoints(self):\n",
        "    points = self.getPointsLeft()\n",
        "    # print(points)\n",
        "    dis_Pos_Goal = distance.euclidean(self.pos, self.goal)\n",
        "    dis_Pos_Point = distance.euclidean(self.pos, self.goal)\n",
        "    dis_Point_Goal = 0\n",
        "    valeu = 0\n",
        "    x = 0.0\n",
        "\n",
        "    if(len(points)==0):\n",
        "        valeu =  dis_Pos_Goal\n",
        "    else:\n",
        "        # Find the distance of the closest point\n",
        "        for ip in points:\n",
        "            if distance.euclidean(self.pos, ip) < dis_Pos_Point:\n",
        "                dis_Pos_Point = distance.euclidean(self.pos, ip)\n",
        "                dis_Point_Goal = distance.euclidean(ip, self.goal)\n",
        "        \n",
        "        # Calculate v\n",
        "        v = dis_Pos_Point + dis_Point_Goal\n",
        "        if dis_Pos_Point == 1:\n",
        "            v=0\n",
        "        if(v>0):\n",
        "            x = dis_Pos_Goal/v\n",
        "        else:\n",
        "            x = 1\n",
        "        # Calculate h2\n",
        "        valeu = dis_Pos_Goal + dis_Pos_Goal*(1-x)\n",
        "    return valeu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xe1hkEvOZgT8"
      },
      "source": [
        "## **5 - Local Beam Search**\n",
        "\n",
        "One of the methods adopted to solve the Pac-man game is the local beam search. It's an algorithm that keeps track of k states. \n",
        "\n",
        "The main objective is to find the goal, and, if the goal isn't found yet, to collect as many points along the path to the goal as possible. \n",
        "\n",
        "Since the local beam search grabs k good neighbor states without thinking ahead about where to go next, this algorithm is greedy. In fact, it tries to increase the objective function defined as the number of collected points (the optimization problem). Under this method, the path to the goal is irrelevant. \n",
        "\n",
        "The way the search method works is that it selects the k best successors according to the number of points they contain. During the search, only k states are kept in memory every time we expand new nodes. This method is particularly suitable for devices with very limited memory. \n",
        "\n",
        "If collecting as many points as possible is important, the local beam search method is an appropriate algorithm for this problem.\n",
        "\n",
        "The steps for this algorithm are the following:\n",
        "\n",
        "\n",
        "1.   We begin with k randomly generated states,\n",
        "2.   All the successors of all the k states are generated,\n",
        "1.   If any of the successors is the goal, the algorithm stops\n",
        "2.   Else we select the k best successors from the complete list of successors ranked by the number of points each node contains, and \n",
        "1.   We repeat the process from step 2\n",
        "\n",
        "An important hypothesis we make is that before starting the local beam search, we have no detail about the map, its size, structure, or any other information that could give a clue about the maze. \n",
        "\n",
        "Also, since the number of possibilities can quickly get high as we progress inside the map, we set a value of 10 for the width. We select the 10 best successors at each time during the search. We choose k = 10 for two reasons. First, we select the best nodes from where to collect points, while having a reasonable chance of finding the goal. If after the search ends, it doesn't find a solution, we increase the value of k by 5 and start a new search from the initial position \"S\". This process continues until the search either finds a solution or k reaches the maximum value of 5010 (at this value, there is reasonable confidence we explored the entire map without finding the goal, provided the map is dense and hasn't a too large size). \n",
        "\n",
        "\n",
        "Again, the local beam search is selected, in this problem, to maximize the objective function which is the number of points collected. By design, during each step, the search selects the k best immediate neighbors of the k current states. The ranking is made according to the number of points each successor contains. Thus, theoretically, we expect that the local beam search will give good results, among all the search methods implemented in the problem, if we consider only the number of points collected.\n",
        "\n",
        "From another perspective, if we imagine a map with points concentrated in a region of the map opposite to the goal, then the search will naturally progress to the region containing those points before heading back to the goal state. As a result, the solution path, according to the local beam search, would end up being longer than the one found by other methods (especially information searches using the Euclidean distance from the current node to the goal state).\n",
        "\n",
        "Since only k nodes are expanded when exploring the map, the path to the goal could be discarded (the unique path to the goal contains no points to collect for instance). Thus, there is no guarantee to find a solution with a given value of k, and therefore the local beam search isn't complete. To solve that issue in the context of the current problem, we start a new search by increasing the value of k until either all of the nodes are explored or we reach a solution. By increasing each time the value of k, we increase the number of successors kept in memory at each step of the process. Thus, the local beam search becomes more and more like the breadth-first search method.  \n",
        "\n",
        "\n",
        "**Completeness:** No, this strategy doesn't guarantee it will find a solution, if a solution exists.\n",
        "\n",
        "**Optimization:** No, this strategy doesn't guarantee it will find the optimal solution (finding the path that collects the maximum number of points possible under the game conditions)\n",
        "\n",
        "**Time complexity:**  $ O(k*d) $ \n",
        "\n",
        "**Memory complexity:**  $ O(k*d) $\n",
        "\n",
        "Below we provide the implementation of the local beam search in Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gbt_e4KWZprS",
        "colab": {}
      },
      "source": [
        "def local_beam_search(problem, k_width):\n",
        "    \"\"\"\n",
        "    From the initial node, Select randomly k states,\n",
        "    From all the successors, select the k neighbors with highest value,\n",
        "    Stopping when goal is found or no more successor\n",
        "    Else repeat process\n",
        "    \"\"\"\n",
        "    current = Node(problem.initial)\n",
        "\n",
        "    if k_width >= len(current.expand(problem)):\n",
        "      k_successors = current.expand(problem)\n",
        "    else:\n",
        "      k_successors = random.sample(current.expand(problem), k=k_width)\n",
        "\n",
        "    #check if there are successors to the k successors selected\n",
        "    if not k_successors:\n",
        "        return None\n",
        "\n",
        "    explored = set()\n",
        "    goal_found = False\n",
        "\n",
        "    while goal_found == False:\n",
        "      all_successors = []\n",
        "\n",
        "      #Generate the successors of all the k best states\n",
        "      for successor in k_successors:\n",
        "        children = successor.expand(problem)\n",
        "        for child in children:\n",
        "          if child.state not in explored and child not in all_successors:\n",
        "            all_successors.append(child)\n",
        "\n",
        "      #if there is no successor, we stop\n",
        "      if not all_successors:\n",
        "        #print(\"No solution found with width =\", k_width)\n",
        "        break\n",
        "\n",
        "      #check if any successor is a goal\n",
        "      for successor in all_successors:\n",
        "        if problem.goal_test(successor.state):\n",
        "          goal_found = True\n",
        "          #print(\"Solution found for width =\", k_width)\n",
        "          return successor\n",
        "\n",
        "      #Select the k best successors\n",
        "      all_successors.sort(key=lambda node: node.state.getPoints(), reverse=True)\n",
        "      k_successors = all_successors[:k_width]\n",
        "\n",
        "      #Mark the k successors as explored, to avoid exploring same nodes\n",
        "      for successor in k_successors:\n",
        "        explored.add(successor.state)\n",
        "\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KtF4GrDDD_Fw"
      },
      "source": [
        "## **5 - Hill Climbing**\n",
        "\n",
        "\n",
        "Hill climbing uses a heuristic to define which is the best node at a given state to expand. In our approach, we use the Euclidian distance and select the node with the smaller value.\n",
        "\n",
        "**Completeness:** No\n",
        "\n",
        "**Optimization:** No\n",
        "\n",
        "**Time complexity:** $ O(b^d)$\n",
        "\n",
        "**Memory complexity:** uses few memory\n",
        "\n",
        "Below we provide the implementation of the local beam search in Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GkpUb0qCEA1p",
        "colab": {}
      },
      "source": [
        "def argmin_random_tie(seq, key=identity):\n",
        "    return min(shuffled(seq), key=key)\n",
        "\n",
        "def shuffled(iterable):\n",
        "    items = list(iterable)\n",
        "    random.shuffle(items)\n",
        "    return items\n",
        "\n",
        "def hill_climbing(problem):\n",
        "    current = Node(problem.initial)\n",
        "    while True:\n",
        "        neighbors = current.expand(problem)\n",
        "        if not neighbors:\n",
        "            break\n",
        "        neighbor = argmin_random_tie(neighbors,\n",
        "                                     key=lambda node: problem.value(node.state))\n",
        "        current = neighbor\n",
        "        if current.state.solved():\n",
        "            break \n",
        "    return current"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pljOnM_HbMI5"
      },
      "source": [
        "# **IV - Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7koszinATrj-",
        "colab_type": "text"
      },
      "source": [
        "### **Simulation Results and Discussion**\n",
        "\n",
        "The figures presented in this section show the mean values derived from 10 independent replications and a confidence intervals of 95%.\n",
        "We compared the strategies in terms of:\n",
        "- Simulated time\n",
        "- Number of generated nodes\n",
        "- Number of points won\n",
        "- Number of points left\n",
        "- Number of actions from the initial position to the goal\n",
        "- Number of expanded nodes\n",
        "- Number of nodes generated nodes per second\n",
        "- Number of expanded nodes per second\n",
        "\n",
        "These metrics were observed into dense and non-dense scenarios. For the sake of clearness, the confidence intervals are omitted, and we analyze only the scenarios with points. The rest of the results (with 0 point scenarios) have similar values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE0Y7JbSTrj-",
        "colab_type": "text"
      },
      "source": [
        "#### **Simulated time**\n",
        "The simulation results show that the computing time is lower for the DFS and Hill because those search methods aim to reach the depth node in the queue. Those mechanisms produce  slightly  lower  delay  values  in non-dense scenarios. They provide a computing time two or three orders of magnitude lower than the others strategies. Moreover, the A*1 search method produces similar values to the DFS and Hill searches in high empty maps (scenarios 11 and 12) because this method aims to find the goal following the Euclidean distance, which is the shortest path. This means that this strategy is similar to DFS in this type of maps.\n",
        "\n",
        "In general, the time increases exponentially with the size of the map. We can find the reason by looking at the graph measuring the nodes per second, and expanded nodes per second. As the map increases in size, those metrics decrease dramatically. The difference between the different search methods  according  to the complexity, type and number of operation(s), every time new nodes are expanded, get even more obvious with increasing map size.\n",
        "\n",
        "<table><tr><td><img src='https://raw.githubusercontent.com/lucaslzl/search_ia_p1/master/plots/with_points/dense_times.png'></td><td><img src='https://raw.githubusercontent.com/lucaslzl/search_ia_p1/master/plots/with_points/nodense_times.png'></td></tr></table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgBieVlFTrj_",
        "colab_type": "text"
      },
      "source": [
        "The local beam search has a relatively average execution time compared to the other methods. In the case of non-dense maps (empty maps), the number of successors increases exponentially (to the order of 3 to the n, in the middle of the maze, far from the walls), when we increase the map size (map size is the same for map 4 and 10, only the distribution of points is different). For the map 11 and 12, the time increased much dramatically. In fact, for those two maps, an iteration over the width k was necessary to find a solution (k=50 for map 11 and k=285 for map12). Incrementing the value of k by 5 on each iteration, from an initial value of 10, until reaching an optimal value of k=50 for map 11 and k=285 for map 12, slowed down the local beam search method. We can note here that it is difficult to choose a \"good\" value for k, map 11 and 12 have the same size, only their structure is different, but the difference in value of the search width is of the order of almost 6.  \n",
        "\n",
        "On the other hand, BFS produce a computation time of 4 second on average for non-dense and dense scenarios. This occurs because the BFS prioritizes the length of the map and not the depth. For most maps, the starting position and the goal position are in opposite side; thus BFS processes all possible paths until reaching the goal.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PyyoSj2dbvuM"
      },
      "source": [
        "### **Number of actions**\n",
        "\n",
        "The Simulation results show that the depth-first search method produces a higher number of actions than the other strategies, for both dense and non-dense scenarios. Those values occur because the search expands the shallowest node, which requires more steps to reach the goal position and also requires a higher computing time, as shown previously.\n",
        "\n",
        "We notice that the local beam search finds a path that is systematically longer than the others found by other methods, except for the depth-first search. Also, the path to the goal, found by the local beam search, increases with the size of the map. Those results confirm our initial expectations. The local beam search is mainly concerned in maximizing its objective function (collecting the maximum number of points).  Moreover, the other strategies produce similar values.\n",
        "\n",
        "<table><tr><td><img src='https://raw.githubusercontent.com/lucaslzl/search_ia_p1/master/plots/with_points/dense_acti.png'></td><td><img src='https://raw.githubusercontent.com/lucaslzl/search_ia_p1/master/plots/with_points/nodense_acti.png'></td></tr></table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjqZ_jURTrkA",
        "colab_type": "text"
      },
      "source": [
        "### **Number of generated nodes**\n",
        "\n",
        "This metric comprehends the amount of generated nodes. Generated nodes are nodes that were checked by the strategy and loaded to memory. Thus, the number of nodes measures the total memory used to perform each search method by counting the total number of nodes kept during the search to find a solution.\n",
        "\n",
        "The Simulation results show that the Hill and BFS search methods produce a lower number of nodes generated in both scenarios.  This occurs because Hill expands the node only to find a better solution.  If the change produces a new change to produce a better solution, another incremental change is made to the new solution, repeating this process until no improvement can be found, which considerably reduces the memory size. Moreover, the DFS produces low memory consumption due to its expansion of nodes in depth. On the other hand, the LBS  selects k best successors every time new nodes are expanded, the memory required by this search is bounded by the width k. As a consequence, for both dense and empty maps, the local beam search required an average memory size compared to the other methods for finding a solution. The only exception to that is for map 11 and 12. Much bigger values of k (50 and 285 respectively), and as a consequence a much higher memory, were necessary to find a solution. Since those maps are empty, the number of new successors, when new nodes are expanded, from which to select a set of k best successors increases exponentially to the order of 3 to the N inside the map. For values of k below 50 and 285, for the maps 11 and 12, the lists of nodes selected are trapped in the bottom half of the map.\n",
        "\n",
        "<table><tr><td><img src='https://raw.githubusercontent.com/lucaslzl/search_ia_p1/master/plots/with_points/dense_nodes.png'></td><td><img src='https://raw.githubusercontent.com/lucaslzl/search_ia_p1/master/plots/with_points/nodense_nodes.png'></td></tr></table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE_p3k2JTrkA",
        "colab_type": "text"
      },
      "source": [
        "### **Number of points win**\n",
        "\n",
        "As mentioned before, one of the objectives is to collect as many points as possible on the map. Therefore, the graphics below present the results of this metric. It describes the average number of points collected by each search method over increasing sizes of the map. As expected, the local beam search is very efficient at collecting points on average (5.8 points collected). It surpasses the other search methods on this metric, for maps that are relatively dense in terms of walls inside it. However, as the map gets bigger, the average number of points collected decreases. In fact, with increasing size, while keeping the total number of points available to collect constant (10 points), the number of nodes expanded gets much bigger, it becomes less probable to find points inside the expanded nodes. Especially if the points are dispersed over the map. In non-dense scenarios, the DFS presents the best results, with an average of 5.0 points collected. Besides, in both approaches, the Hill strategy presents the worst result, averaging 0.2 points collected\n",
        "\n",
        "\n",
        "<table><tr><td><img src='https://raw.githubusercontent.com/lucaslzl/search_ia_p1/master/plots/with_points/dense_pont.png'></td><td><img src='https://raw.githubusercontent.com/lucaslzl/search_ia_p1/master/plots/with_points/nodense_pont.png'></td></tr></table>\n",
        "\n",
        "The simulation results show that the points left metric (not collected in the path) experiences opposite behavior to the points won metric (figures not shows in this report). In addition, the DFS and LBS strategies present the best result again in dense and non-dense scenarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UajXOgvTrkB",
        "colab_type": "text"
      },
      "source": [
        "### **Number of expanded nodes**\n",
        "\n",
        "The simulation results show that the BFS and Hill search methods expand on average  30 and 10  nodes, non-dense scenarios, respectively. These values are two or three order of magnitudes lower than the other strategies, such as BFS, which expand on average 30000 nodes.  In the worst case scenario (map 2), BFS expanded 100000 nodes.\n",
        "\n",
        "<table><tr><td><img src='https://raw.githubusercontent.com/lucaslzl/search_ia_p1/master/plots/with_points/dense_expa.png'></td><td><img src='https://raw.githubusercontent.com/lucaslzl/search_ia_p1/master/plots/with_points/nodense_expa.png'></td></tr></table>\n",
        "\n",
        "However, this expansion node metric is subjective to the performance evaluation because some methods expand the nodes faster. For example, A*2 expands the same number of nodes as BFS  in the scenario; however, the time to expand the nodes is lower (being  800 per second and 5000 nodes) for A*2 and BFS respectively, as shown in the following figures.\n",
        "\n",
        "<table><tr><td><img src='https://raw.githubusercontent.com/lucaslzl/search_ia_p1/master/plots/with_points/dense_expanded_per_sec.png'></td><td><img src='https://raw.githubusercontent.com/lucaslzl/search_ia_p1/master/plots/with_points/nodense_expanded_per_sec.png'></td></tr></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCN3gRUaTrkB",
        "colab_type": "text"
      },
      "source": [
        "### **Maps with no points:**\n",
        "\n",
        "We won't discuss the results of the local beam search on maps with no points to collect. Given the objective of this method and the way it is implemented, discussing its results with the objective function set to 0 over the map makes no sense.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9LVC847sbgdq"
      },
      "source": [
        "# **V - Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yONZQNhdbxNU"
      },
      "source": [
        "In most cases, the Hill search method finds a solution with the lowest cost in terms of time and number of actions to reach the goal from the starting position. However, for non-dense maps, the BFS produces similar values to the Hill search method. Moreover, LBS finds a solution only if we set a large value of the width k. This means that the search wasted time finding a solution with previously lower values of k. It is possible to find \"rules\" to select an appropriate width range for \"k\". However, this wouldn't have been an \"elegant\" implementation for this algorithm and more importantly we don't have any information about the map initially. We preferred, in this problem, to adopt the most simpler option, incrementing the value of k until the local beam search finds a solution.\n",
        "\n",
        "Finally, for more complex problems in general, when adopting LBS, we could keep in memory the number of possibilities at each time we expand new successors. If we don't find a solution the first time we run the algorithm, that memorized number could help us select an adequate value of the next width to increase the probability of finding a solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hc-yvZ4qbkgh"
      },
      "source": [
        "# **VII - Sources**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BNaIIOCybT5w"
      },
      "source": [
        "[1] https://en.wikipedia.org/wiki/Pac-Man\n",
        "\n",
        "[2] https://github.com/aimacode/aima-python/blob/master/search.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4ZoBou07ccjB"
      },
      "source": [
        "# **Appendix**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DKmvicAwi-go"
      },
      "source": [
        "## **Link to the Github repository**\n",
        "\n",
        "[https://github.com/lucaslzl/search_ia_p1](https://github.com/lucaslzl/search_ia_p1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WLbCPh82cinS"
      },
      "source": [
        "## **Link to the video**\n",
        "\n",
        "https://www.youtube.com/watch?v=ffuthDRn6lE&feature=youtu.be"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j-5pz-oTgjGY"
      },
      "source": [
        "## **How to execute the files**\n",
        "\n",
        "There are two ways to execute the experiments:\n",
        "\n",
        "**1. Execute the python code called \"main.py\" and pass the parameters**\n",
        "\n",
        "The code considers the parameters to execute each strategy and map. It is possible to change how many times it executes and to print or not the results.\n",
        "\n",
        "Run \"python3 main.py --(strategy flag)\" to execute.\n",
        "\n",
        "For instance, \"python main.py --bfs --maps=./maps/map1.txt,./maps/map2.txt\" executes both files with bfs.\n",
        "\n",
        "It is worth to point out that you may run \"python main.py --help\" to visualize all the possible flags and parameters.\n",
        "\n",
        "To see the state after applying each action add the tag \"--print\"\n",
        "\n",
        "**2. Execute the shellcode called \"execute.sh\"**\n",
        "\n",
        "The code executes every strategy in each map 10 times and saves the results. Besides, a code called \"compute.py\" read all outputs and calculate distinct metrics.\n",
        "\n",
        "run \"./execute.sh\" and wait until it is done.\n",
        "\n",
        "All results are saved in the results folder as the \"computer.py\" code.\n",
        "\n",
        "Good idea to use virtual env. Tested on Python 3.8"
      ]
    }
  ]
}